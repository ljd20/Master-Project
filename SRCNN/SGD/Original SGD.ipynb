{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN5L12Cz+2Urq/itpF/kUzR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"qjdILrVLteBH"},"outputs":[],"source":["continue_training_epochs = 100  # Number of additional epochs to run\n","model_checkpoint = 'SRCNN_checkpoint_epoch_199.pth'  # Specify the checkpoint file to continue from\n","# model_checkpoint = None\n","\n","import os\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, datasets\n","from torchvision.utils import save_image, make_grid\n","import matplotlib.pyplot as plt\n","import tqdm\n","from PIL import Image\n","from google.colab import drive\n","from pathlib import Path\n","\n","%load_ext google.colab.data_table\n","\n","class Config():\n","    SRCNN_path = 'SRCNN/'\n","    content_path = f'/content/drive/MyDrive/{SRCNN_path}'\n","    data_path = './data/'\n","\n","    content_path = Path(content_path)\n","\n","    GPU = True\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() and GPU else \"cpu\")\n","\n","    batch_size = 16\n","    num_epochs = continue_training_epochs\n","\n","    transform = transforms.Compose([\n","        transforms.Resize(224),\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n","    ])\n","\n","    @staticmethod\n","    def low_res_transform():\n","        return transforms.Compose([\n","            transforms.GaussianBlur(kernel_size=(5, 5), sigma=(1.5, 1.5)),\n","            transforms.Resize(224 // 3, interpolation=transforms.InterpolationMode.BICUBIC),\n","            transforms.Resize(224, interpolation=transforms.InterpolationMode.BICUBIC),\n","        ])\n","\n","    hr_train_dir = content_path / 'DIV2K_train_HR'\n","    hr_val_dir = content_path / 'DIV2K_valid_HR'\n","\n","class Setup():\n","    def __init__(self, config):\n","        self.config = config\n","        self.mount()\n","        self.make_dir()\n","        self.seed()\n","\n","    def mount(self):\n","        drive.mount('/content/drive/')\n","\n","    def make_dir(self):\n","        if not os.path.exists(self.config.content_path / 'Models/'):\n","            os.makedirs(self.config.content_path / 'Models/')\n","        if not os.path.exists(self.config.data_path):\n","            os.makedirs(self.config.data_path)\n","\n","    def seed(self):\n","        if torch.cuda.is_available():\n","            torch.backends.cudnn.deterministic = True\n","            torch.manual_seed(0)\n","\n","class SRDataset(Dataset):\n","    def __init__(self, hr_image_dir, transform=None, low_res_transform=None):\n","        self.hr_image_dir = hr_image_dir\n","        self.hr_image_filenames = os.listdir(hr_image_dir)\n","        self.transform = transform\n","        self.low_res_transform = low_res_transform\n","\n","    def __len__(self):\n","        return len(self.hr_image_filenames)\n","\n","    def __getitem__(self, idx):\n","        hr_image_path = os.path.join(self.hr_image_dir, self.hr_image_filenames[idx])\n","        hr_image = Image.open(hr_image_path).convert('RGB')\n","\n","        if self.transform:\n","            hr_image = self.transform(hr_image)\n","\n","        lr_image = self.low_res_transform(hr_image) if self.low_res_transform else hr_image\n","\n","        return lr_image, hr_image\n","\n","class SRCNN(nn.Module):\n","    def __init__(self):\n","        super(SRCNN, self).__init__()\n","        self.patch_extraction = nn.Sequential(\n","            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=9, padding=4),\n","            nn.ReLU()\n","        )\n","        self.non_linear_mapping = nn.Sequential(\n","            nn.Conv2d(in_channels=64, out_channels=32, kernel_size=5, padding=2),\n","            nn.ReLU()\n","        )\n","        self.reconstruction = nn.Sequential(\n","            nn.Conv2d(in_channels=32, out_channels=3, kernel_size=5, padding=2),\n","        )\n","        self.initialise_weights()\n","\n","    def initialise_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.normal_(m.weight, mean=0.0, std=0.001)\n","                nn.init.constant_(m.bias, 0)\n","\n","    def forward(self, x):\n","        x = self.patch_extraction(x)\n","        x = self.non_linear_mapping(x)\n","        x = self.reconstruction(x)\n","        return x\n","\n","class SRCNNTrainer():\n","    def __init__(self, config):\n","        self.config = config\n","        self.device = config.device\n","        self.batch_size = config.batch_size\n","        self.num_epochs = config.num_epochs\n","        self.transform = config.transform\n","        self.low_res_transform = config.low_res_transform()\n","        self.psnr = {'Train': [], 'Validate': []}\n","        self.loss = {'Train': [], 'Validate': []}\n","        self.model = SRCNN().to(self.device)\n","        self.optimizer = self.initialise_optimizer()\n","        self.train_dataloader, self.val_dataloader = self.initialise_dataset()\n","\n","    def initialise_optimizer(self):\n","        params_to_optimize = [\n","            {\"params\": self.model.patch_extraction.parameters(), \"lr\": 1e-4},\n","            {\"params\": self.model.non_linear_mapping.parameters(), \"lr\": 1e-4},\n","            {\"params\": self.model.reconstruction.parameters(), \"lr\": 1e-5}\n","        ]\n","        optimizer = torch.optim.SGD(params=params_to_optimize, momentum=0.9)\n","        return optimizer\n","\n","\n","    def initialise_dataset(self):\n","        train_dataset = SRDataset(self.config.hr_train_dir, transform=self.transform, low_res_transform=self.low_res_transform)\n","        train_dataloader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n","        val_dataset = SRDataset(self.config.hr_val_dir, transform=self.transform, low_res_transform=self.low_res_transform)\n","        val_dataloader = DataLoader(val_dataset, batch_size=self.batch_size, shuffle=False)\n","        return train_dataloader, val_dataloader\n","\n","    def model_output(self):\n","        params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n","        print(\"Total number of parameters is: {}\".format(params))\n","        print(self.model)\n","\n","    def loss_MSE(self, input, target):\n","        loss = nn.MSELoss()\n","        mse_loss = loss(input, target)\n","        max_pixel = 1.0\n","        psnr = 20 * torch.log10(max_pixel / torch.sqrt(mse_loss))\n","        return mse_loss, psnr\n","\n","    def save_checkpoint(self, epoch):\n","        checkpoint_path = self.config.content_path / f'Models/SRCNN_checkpoint_epoch_{epoch}.pth'\n","        torch.save({\n","            'epoch': epoch,\n","            'model_state_dict': self.model.state_dict(),\n","            'optimizer_state_dict': self.optimizer.state_dict(),\n","            'loss': self.loss,\n","            'psnr': self.psnr\n","        }, checkpoint_path)\n","\n","    def load_checkpoint(self, checkpoint_path):\n","        if checkpoint_path.exists():\n","            checkpoint = torch.load(checkpoint_path)\n","            self.model.load_state_dict(checkpoint['model_state_dict'])\n","            self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","            self.loss = checkpoint['loss']\n","            self.psnr = checkpoint['psnr']\n","            start_epoch = checkpoint['epoch'] + 1\n","            return start_epoch\n","        else:\n","            return 0\n","\n","    def save_metrics(self):\n","        metrics_path = self.config.content_path / 'Models/metrics.txt'\n","        with open(metrics_path, 'w') as f:\n","            for epoch in range(len(self.loss['Train'])):\n","                if epoch % 20 == 0 or epoch == len(self.loss['Train']) - 1:\n","                    f.write(f\"Epoch {epoch}:\\n\")\n","                    f.write(f\"Train Loss: {self.loss['Train'][epoch]}\\n\")\n","                    f.write(f\"Train PSNR: {self.psnr['Train'][epoch]}\\n\")\n","                    f.write(f\"Validate Loss: {self.loss['Validate'][epoch]}\\n\")\n","                    f.write(f\"Validate PSNR: {self.psnr['Validate'][epoch]}\\n\")\n","\n","    def training(self, checkpoint_path):\n","        start_epoch = self.load_checkpoint(checkpoint_path)\n","        self.model.train()\n","        try:\n","            for epoch in range(start_epoch, start_epoch + self.num_epochs):\n","                training_loss = 0\n","                psnr_total = 0\n","                with tqdm.tqdm(self.train_dataloader, unit=\"batch\") as tepoch:\n","                    for batch_idx, (low, high) in enumerate(tepoch):\n","                        high_res = high.to(self.device)\n","                        low_res = low.to(self.device)\n","                        self.optimizer.zero_grad()\n","                        reconstructed_images = self.model(low_res)\n","                        loss, psnr = self.loss_MSE(reconstructed_images, high_res)\n","                        loss.backward()\n","                        psnr_total += psnr.item()\n","                        training_loss += loss.item()\n","                        self.optimizer.step()\n","                        if batch_idx % 20 == 0:\n","                            tepoch.set_description(f\"Epoch {epoch}\")\n","                            tepoch.set_postfix(loss=loss.item()/len(high_res), psnr=psnr.item())\n","                self.psnr['Train'].append(psnr_total/len(tepoch))\n","                self.loss['Train'].append(training_loss/len(tepoch))\n","                self.validate()\n","                if epoch % 20 == 0 or epoch == start_epoch + self.num_epochs - 1:\n","                    self.save_checkpoint(epoch)\n","            self.save_metrics()\n","        except Exception as e:\n","            print(f\"Training interrupted at epoch {epoch}: {e}\")\n","            self.save_checkpoint(epoch)\n","\n","    def validate(self):\n","        self.model.eval()\n","        with torch.no_grad():\n","            valid_loss = 0\n","            psnr_total = 0\n","            with tqdm.tqdm(self.val_dataloader, unit=\"batch\") as tepoch:\n","                for batch_idx, (low, high) in enumerate(tepoch):\n","                    high_res = high.to(self.device)\n","                    low_res = low.to(self.device)\n","                    reconstructed_images = self.model(low_res)\n","                    loss, psnr = self.loss_MSE(reconstructed_images, high_res)\n","                    valid_loss += loss.item()\n","                    psnr_total += psnr.item()\n","                    if batch_idx % 20 == 0:\n","                        tepoch.set_description(f\"Test\")\n","                        tepoch.set_postfix(loss=loss.item()/len(high_res))\n","            self.psnr['Validate'].append(psnr_total/len(tepoch))\n","            self.loss['Validate'].append(valid_loss/len(tepoch))\n","\n","class Results():\n","    def __init__(self, model, device, content_path):\n","        self.model = model\n","        self.device = device\n","        self.content_path = content_path\n","\n","    def denorm(self, x):\n","        device = x.device\n","        mean = torch.tensor([0.5, 0.5, 0.5], device=device).view(3, 1, 1)\n","        std = torch.tensor([0.5, 0.5, 0.5], device=device).view(3, 1, 1)\n","        x = x * std + mean\n","        return x\n","\n","    def display_dataset(self, val_dataloader, low_res_transform):\n","        sample_inputs, _ = next(iter(val_dataloader))\n","        fixed_input = sample_inputs[0:32, :, :, :]\n","        # visualize the original images of the last batch of the test set\n","        img = make_grid(self.denorm(fixed_input), nrow=8, padding=2, normalize=False,\n","                        value_range=None, scale_each=False, pad_value=0)\n","        plt.figure()\n","        self.show(img)\n","        plt.savefig(self.content_path / \"high_res.png\")\n","\n","        sample_inputs, _ = next(iter(val_dataloader))\n","        fixed_input = sample_inputs[0:32, :, :, :]\n","        # visualize the original images of the last batch of the test set\n","        img = make_grid(self.denorm(low_res_transform(fixed_input)), nrow=8, padding=2, normalize=False,\n","                        value_range=None, scale_each=False, pad_value=0)\n","        plt.figure()\n","        self.show(img)\n","        plt.savefig(self.content_path / \"low_res.png\")\n","\n","        print('-' * 50)\n","        with torch.no_grad():\n","            recon_batch = self.model(fixed_input.to(self.device))\n","            recon_batch = recon_batch.cpu()\n","            recon_batch = make_grid(self.denorm(recon_batch), nrow=8, padding=2, normalize=False,\n","                                    value_range=None, scale_each=False, pad_value=0)\n","            plt.figure()\n","            self.show(recon_batch)\n","            plt.savefig(self.content_path / \"recon_images.png\")\n","\n","    def plot_loss_psnr(self, psnr, loss):\n","        plt.figure(figsize=(9, 6))\n","        plt.plot(psnr['Train'], color='red', label='PSNR')\n","        plt.title(\"PSNR - Training\")\n","        plt.xlabel('Epochs')\n","        plt.ylabel('PSNR')\n","        plt.legend()\n","        plt.savefig(self.content_path / \"training_psnr.png\")\n","\n","        plt.figure(figsize=(9, 6))\n","        plt.plot(loss['Train'], color='blue', label='Loss')\n","        plt.title(\"Loss - Training\")\n","        plt.xlabel('Epochs')\n","        plt.ylabel('Loss')\n","        plt.legend()\n","        plt.savefig(self.content_path / \"training_loss.png\")\n","\n","        plt.figure(figsize=(9, 6))\n","        plt.plot(psnr['Validate'], color='red', label='PSNR')\n","        plt.title(\"PSNR - Validate\")\n","        plt.xlabel('Epochs')\n","        plt.ylabel('PSNR')\n","        plt.legend()\n","        plt.savefig(self.content_path / \"validate_psnr.png\")\n","\n","        plt.figure(figsize=(9, 6))\n","        plt.plot(loss['Validate'], color='blue', label='Loss')\n","        plt.title(\"Loss - Validate\")\n","        plt.xlabel('Epochs')\n","        plt.ylabel('Loss')\n","        plt.legend()\n","        plt.savefig(self.content_path / \"validate_loss.png\")\n","\n","    def show(self, img):\n","        npimg = img.cpu().numpy()\n","        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n","\n","class ImageProcessor():\n","    def __init__(self, model, device, content_path):\n","        self.model = model\n","        self.device = device\n","        self.content_path = content_path\n","\n","    def load_image(self, image_path):\n","        img = Image.open(image_path).convert('RGB')\n","        transform = transforms.Compose([\n","            transforms.Resize(224),\n","            transforms.CenterCrop(224),\n","            transforms.ToTensor(),\n","        ])\n","        img = transform(img).unsqueeze(0)\n","        return img\n","\n","    def process_image(self, image_path):\n","        img = self.load_image(image_path)\n","        img = img.to(self.device)\n","        self.model.eval()\n","        with torch.no_grad():\n","            output = self.model(img)\n","\n","        denorm_output = self.denorm(output)\n","        output = torch.nn.functional.interpolate(denorm_output, size=(224, 224), mode='bilinear', align_corners=False)\n","        input_image = torch.nn.functional.interpolate(self.denorm(img), size=(224, 224), mode='bilinear', align_corners=False)\n","        return input_image, output\n","\n","    def denorm(self, x):\n","        device = x.device\n","        mean = torch.tensor([0.5, 0.5, 0.5], device=device).view(3, 1, 1)\n","        std = torch.tensor([0.5, 0.5, 0.5], device=device).view(3, 1, 1)\n","        x = x * std + mean\n","        return x\n","\n","    def display_and_save_image(self, input_image, output_image):\n","        recon_batch = make_grid(output_image, nrow=8, padding=2, normalize=False, value_range=None, scale_each=False, pad_value=0)\n","        image_output = make_grid(input_image, nrow=8, padding=2, normalize=False, value_range=None, scale_each=False, pad_value=0)\n","\n","        plt.figure()\n","        self.show(image_output)\n","        plt.figure()\n","        self.show(recon_batch)\n","\n","        save_image(output_image, os.path.join(self.content_path, 'reconstructed_image.png'))\n","\n","    def show(self, img):\n","        npimg = img.cpu().numpy()\n","        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n","\n","def main():\n","    config = Config()\n","    setup = Setup(config)\n","    trainer = SRCNNTrainer(config)\n","    checkpoint_path = config.content_path / f'SGD/{model_checkpoint}'\n","    start_epoch = trainer.load_checkpoint(checkpoint_path)\n","    if start_epoch == 0:\n","        print(\"No checkpoint found. Training from scratch.\")\n","    trainer.training(checkpoint_path)\n","\n","    tester = Results(trainer.model, trainer.device, config.content_path)\n","    tester.display_dataset(trainer.val_dataloader, trainer.low_res_transform)\n","    tester.plot_loss_psnr(trainer.psnr, trainer.loss)\n","\n","if __name__ == \"__main__\":\n","    main()\n"]}]}