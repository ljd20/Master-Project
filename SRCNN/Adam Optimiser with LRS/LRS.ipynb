{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"elapsed":1463220,"status":"ok","timestamp":1718039174470,"user":{"displayName":"Louise Davis","userId":"12685913776521059576"},"user_tz":-60},"id":"7JN_abo6ds7I","outputId":"0a659468-a49d-4a30-9d20-906db107bdcd"},"outputs":[],"source":["import os\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, datasets\n","from torchvision.utils import save_image, make_grid\n","import matplotlib.pyplot as plt\n","import tqdm\n","from PIL import Image\n","from google.colab import drive\n","from pathlib import Path\n","\n","%load_ext google.colab.data_table\n","\n","# configuration setup\n","class Config():\n","    SRCNN_path = 'SRCNN/'\n","    content_path = f'/content/drive/MyDrive/{SRCNN_path}'\n","    data_path = './data/'\n","\n","    content_path = Path(content_path)\n","\n","    GPU = True\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() and GPU else \"cpu\")\n","\n","    batch_size = 16\n","    num_epochs = 100\n","    # Change this file path to change checkpoint model\n","    # Set to \"None\" to start training from scratch\n","    checkpoint_path = content_path / 'Models/SRCNN_checkpoint.pth\n","\n","    # tranforms high-resolution images\n","    transform = transforms.Compose([\n","        transforms.Resize(224),\n","        transforms.CenterCrop(224),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n","    ])\n","\n","    # converts high-resolution to low-resolution\n","    @staticmethod\n","    def low_res_transform():\n","        return transforms.Compose([\n","            transforms.GaussianBlur(kernel_size=(5, 5), sigma=(1.5, 1.5)), # Gaussian blur\n","            transforms.Resize(224 // 3, interpolation=transforms.InterpolationMode.BICUBIC),\n","            transforms.Resize(224, interpolation=transforms.InterpolationMode.BICUBIC),\n","        ])\n","\n","    hr_train_dir = content_path / 'DIV2K_train_HR'\n","    hr_val_dir = content_path / 'DIV2K_valid_HR'\n","\n","# Setup drive paths\n","class Setup():\n","    def __init__(self, config):\n","        self.config = config\n","        self.mount()\n","        self.make_dir()\n","        self.seed()\n","\n","    def mount(self):\n","        drive.mount('/content/drive/')\n","\n","    def make_dir(self):\n","        if not os.path.exists(self.config.content_path / 'Models/'):\n","            os.makedirs(self.config.content_path / 'Models/')\n","        if not os.path.exists(self.config.data_path):\n","            os.makedirs(self.config.data_path)\n","\n","    def seed(self):\n","        if torch.cuda.is_available():\n","            torch.backends.cudnn.deterministic = True\n","            torch.manual_seed(0)\n","\n","# Setup dataset\n","class SRDataset(Dataset):\n","    def __init__(self, hr_image_dir, transform=None, low_res_transform=None):\n","        self.hr_image_dir = hr_image_dir\n","        self.hr_image_filenames = os.listdir(hr_image_dir)\n","        self.transform = transform\n","        self.low_res_transform = low_res_transform\n","\n","    def __len__(self):\n","        return len(self.hr_image_filenames)\n","\n","    def __getitem__(self, idx):\n","        hr_image_path = os.path.join(self.hr_image_dir, self.hr_image_filenames[idx])\n","        hr_image = Image.open(hr_image_path).convert('RGB')\n","\n","        if self.transform:\n","            hr_image = self.transform(hr_image)\n","\n","        lr_image = self.low_res_transform(hr_image) if self.low_res_transform else hr_image\n","\n","        return lr_image, hr_image\n","\n","# SRCNN model\n","class SRCNN(nn.Module):\n","    def __init__(self):\n","        super(SRCNN, self).__init__()\n","        self.patch_extraction = nn.Sequential(\n","            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=9, padding=4),\n","            nn.ReLU()\n","        )\n","        self.non_linear_mapping = nn.Sequential(\n","            nn.Conv2d(in_channels=64, out_channels=32, kernel_size=5, padding=2),\n","            nn.ReLU()\n","        )\n","        self.reconstruction = nn.Sequential(\n","            nn.Conv2d(in_channels=32, out_channels=3, kernel_size=5, padding=2),\n","        )\n","        self.initialise_weights()\n","\n","    # initialises weights\n","    def initialise_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.normal_(m.weight, mean=0.0, std=0.001)\n","                nn.init.constant_(m.bias, 0)\n","    \n","    # performs a forward pass on the network\n","    def forward(self, x):\n","        x = self.patch_extraction(x)\n","        x = self.non_linear_mapping(x)\n","        x = self.reconstruction(x)\n","        return x\n","\n","# SRCNN Training process\n","class SRCNNTrainer():\n","    def __init__(self, config):\n","        self.config = config\n","        self.device = config.device\n","        self.batch_size = config.batch_size\n","        self.num_epochs = config.num_epochs\n","        self.transform = config.transform\n","        self.low_res_transform = config.low_res_transform()\n","        self.psnr = {'Train': [], 'Validate': []}\n","        self.loss = {'Train': [], 'Validate': []}\n","        self.model = SRCNN().to(self.device)\n","        self.optimizer, self.scheduler = self.initialise_optimizer()\n","        self.train_dataloader, self.val_dataloader = self.initialise_dataset()\n","\n","    # optimiser with LRS\n","    def initialise_optimizer(self):\n","        params_to_optimize = [\n","            {\"params\": self.model.patch_extraction.parameters(), \"lr\": 1e-4, \"weight_decay\": 1e-6},\n","            {\"params\": self.model.non_linear_mapping.parameters(), \"lr\": 1e-4, \"weight_decay\": 1e-6},\n","            {\"params\": self.model.reconstruction.parameters(), \"lr\": 1e-5, \"weight_decay\": 1e-6}\n","        ]\n","        optimizer = torch.optim.Adam(params_to_optimize)\n","        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)  # Adjust the learning rate every 50 epochs\n","        return optimizer, scheduler\n","\n","    # initialise the training dataset\n","    def initialise_dataset(self):\n","        train_dataset = SRDataset(self.config.hr_train_dir, transform=self.transform, low_res_transform=self.low_res_transform)\n","        train_dataloader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True)\n","        val_dataset = SRDataset(self.config.hr_val_dir, transform=self.transform, low_res_transform=self.low_res_transform)\n","        val_dataloader = DataLoader(val_dataset, batch_size=self.batch_size, shuffle=False)\n","        return train_dataloader, val_dataloader\n","\n","    # Number of parameter in model\n","    def model_output(self):\n","        params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n","        print(\"Total number of parameters is: {}\".format(params))\n","        print(self.model)\n","\n","    # MSE loss\n","    def loss_MSE(self, input, target):\n","        loss = nn.MSELoss()\n","        mse_loss = loss(input, target)\n","        max_pixel = 1.0\n","        psnr = 20 * torch.log10(max_pixel / torch.sqrt(mse_loss))\n","        return mse_loss, psnr\n","\n","    # save checkpoint model in training\n","    def save_checkpoint(self, epoch):\n","        checkpoint_path = self.config.content_path / f'Models/SRCNN_checkpoint_epoch_{epoch}.pth'\n","        torch.save({\n","            'epoch': epoch,\n","            'model_state_dict': self.model.state_dict(),\n","            'optimizer_state_dict': self.optimizer.state_dict(),\n","            'scheduler_state_dict': self.scheduler.state_dict(),\n","            'loss': self.loss,\n","            'psnr': self.psnr\n","        }, checkpoint_path)\n","\n","    # loads checkpoint model for training\n","    def load_checkpoint(self, checkpoint_path):\n","        if checkpoint_path.exists():\n","            checkpoint = torch.load(checkpoint_path)\n","            self.model.load_state_dict(checkpoint['model_state_dict'])\n","            self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","            self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])  # Load scheduler state\n","            self.loss = checkpoint['loss']\n","            self.psnr = checkpoint['psnr']\n","            start_epoch = checkpoint['epoch'] + 1\n","            return start_epoch\n","        else:\n","            return 0\n","    \n","    # saves model metrics to .txt file\n","    def save_metrics(self):\n","        metrics_path = self.config.content_path / 'Models/metrics.txt'\n","        with open(metrics_path, 'w') as f:\n","            for epoch in range(len(self.loss['Train'])):\n","                if epoch % 20 == 0 or epoch == len(self.loss['Train']) - 1:\n","                    f.write(f\"Epoch {epoch}:\\n\")\n","                    f.write(f\"Train Loss: {self.loss['Train'][epoch]}\\n\")\n","                    f.write(f\"Train PSNR: {self.psnr['Train'][epoch]}\\n\")\n","                    f.write(f\"Validate Loss: {self.loss['Validate'][epoch]}\\n\")\n","                    f.write(f\"Validate PSNR: {self.psnr['Validate'][epoch]}\\n\")\n","\n","    # Train loop\n","    def training(self, checkpoint_path):\n","        start_epoch = self.load_checkpoint(checkpoint_path)\n","        self.model.train()\n","        try:\n","            for epoch in range(start_epoch, start_epoch + self.num_epochs):\n","                training_loss = 0\n","                psnr_total = 0\n","                with tqdm.tqdm(self.train_dataloader, unit=\"batch\") as tepoch:\n","                    for batch_idx, (low, high) in enumerate(tepoch):\n","                        high_res = high.to(self.device)\n","                        low_res = low.to(self.device)\n","                        self.optimizer.zero_grad()\n","                        reconstructed_images = self.model(low_res)\n","                        loss, psnr = self.loss_MSE(reconstructed_images, high_res)\n","                        loss.backward()\n","                        psnr_total += psnr.item()\n","                        training_loss += loss.item()\n","                        self.optimizer.step()\n","                        if batch_idx % 20 == 0:\n","                            tepoch.set_description(f\"Epoch {epoch}\")\n","                            tepoch.set_postfix(loss=loss.item()/len(high_res), psnr=psnr.item())\n","                self.psnr['Train'].append(psnr_total/len(tepoch))\n","                self.loss['Train'].append(training_loss/len(tepoch))\n","                self.scheduler.step()\n","                self.validate()\n","                if epoch % 20 == 0 or epoch == start_epoch + self.num_epochs - 1:\n","                    self.save_checkpoint(epoch)\n","            self.save_metrics()\n","        except Exception as e:\n","            print(f\"Training interrupted at epoch {epoch}: {e}\")\n","            self.save_checkpoint(epoch)\n","\n","    # Validation loop\n","    def validate(self):\n","        self.model.eval()\n","        valid_loss = 0\n","        psnr_total = 0\n","        with torch.no_grad():\n","            with tqdm.tqdm(self.val_dataloader, unit=\"batch\") as tepoch:\n","                for batch_idx, (low, high) in enumerate(tepoch):\n","                    high_res = high.to(self.device)\n","                    low_res = low.to(self.device)\n","                    reconstructed_images = self.model(low_res)\n","                    loss, psnr = self.loss_MSE(reconstructed_images, high_res)\n","                    valid_loss += loss.item()\n","                    psnr_total += psnr.item()\n","                    if batch_idx % 20 == 0:\n","                        tepoch.set_description(f\"Test\")\n","                        tepoch.set_postfix(loss=loss.item()/len(high_res))\n","            self.psnr['Validate'].append(psnr_total/len(tepoch))\n","            self.loss['Validate'].append(valid_loss/len(tepoch))\n","\n","def main():\n","    config = Config()\n","    setup = Setup(config)\n","    trainer = SRCNNTrainer(config)\n","    trainer.training()\n","\n","if __name__ == \"__main__\":\n","    main()"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMjov4QhRV03C+RORLnjm+/","gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
